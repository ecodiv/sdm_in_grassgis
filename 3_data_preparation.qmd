# Prepare the data {#sec-dataprep}

Species distribution models (SDMs) are built using two main types of data. Location data show where a species has been observed, while environmental data describe the conditions in those places. Working with these data is an essential part of SDM, but it can also be challenging. Common issues include uneven sampling of observations, overlap between environmental variables, changes in relationships between variables across datasets, and environmental conditions in the prediction area that were not present in the training data @jarnevich2015.

In this chapter, you will learn a number of simple and practical strategies to recognise and address some of these issues. The methods presented here are not exhaustive, and there is rarely a single “correct” solution. Instead, the goal is to help you develop a critical and thoughtful approach to modelling, and to encourage you to explore, test, and compare different choices as you build and interpret your own SDMs.

## Species occurrences {#sec-specoc}

::::: grid
::: {.g-col-md-6 .g-col-12}
One fundamental assumption of SDMs is that the entire area of interest has been systematically or randomly sampled [@phillips2009a; @kramerSampling2013]. In reality, this assumption is rarely met. Species occurrence data are often affected by sampling bias, meaning that some parts of the study area are sampled more intensively than others. For example, some areas may be more accessible (@fig-examplesofbias) or more popular with visitors, resulting in more data from those locations. Another source of bias comes from intensive monitoring in certain areas. 

This can lead to **oversampling** in some areas, making the conditions in these areas appear to be more suitable for the species, even though the higher number of observations mainly reflects where people are more likely to collect data.

There are several ways to deal with oversampling, focusing on the presence points (this paragraph) or the background points (next paragraph) [@kramerSampling2013; @fourcade2014].
:::

::: {.g-col-md-6 .g-col-12}
![Examples of different potential sources of bias in the species occurrence data for *Erebia alberganus*. On the right side of the map, the points are conspicuously clustered along a road, which may indicate sampling bias. On the left, the points form a grid-like pattern, suggesting that the coordinates were recorded with limited decimal precision.](images/examplesofbias.png){#fig-examplesofbias width="500"}
:::
:::::

Another important issue is **undersampling**, which occurs when parts of the study area are rarely or never visited, for example because they are difficult to access. In undersampled areas, environmental conditions may appear to be less suitable for the species simply because no observations are available. This does not necessarily mean that the species is absent. In many cases, we cannot distinguish between true absence and lack of sampling.

Undersampling is particularly difficult to address when large parts of a species’ potential range have not been sampled adequately. This uncertainty directly affects how confidently model predictions can be interpreted for those areas.

Although it does not solve the problem, comparing GBIF occurrence data with other information sources, such as Red List range maps (@fig-rangemapoccurrences), can help you assess where undersampling is likely to occur and how it is distributed across the study area.

### Point densities {#sec-pointdensities}

Before proceeding, let's check whether our GBIF occurrence dataset shows any signs of bias by analyzing how the density of occurrences varies across the study area. We can do this by counting the number of observations within each grid cell. To accomplish this, we will use the [r.vect.stats](https://grass.osgeo.org/grass-stable/manuals/addons/r.vect.stats.html) module. It is one of the addons installed in @sec-addons. With the module we can create a raster layer with per raster cell the number of points from a vector point layer that fall within that cell.

We want to create the layer in the [Erebia_alberganus]{.style-data} mapset, so we switch to that mapset first. 

::: {#exm-3Tw6fEB0hg .hiddendiv}
:::

::: {.panel-tabset}
## {{< fa solid terminal >}}

``` bash
g.mapset mapset=Erebia_alberganus
```

## {{< fa brands python >}}

``` python
gs.run_command("g.mapset", mapset="Erebia_alberganus")
```

## {{< fa regular window-restore >}}

![To change the mapset, right click on the name of the mapset in the [Data]{.style-menu} panel. In the context menu, select [Switch mapset]{.style-menu}.](images/switchmapset.png){#fig-switchmapset fig-align="left"}
:::

The raster layer that will be created with `v.vect.stats` should cover the same spatial extent as the point data and use the same spatial resolution as the bioclimatic layers, which is 2.5 arc degrees. To ensure this, we need to set the computational region accordingly (remember, the computational region defines the extent and resolution for raster operations in GRASS GIS).

We use the [g.region](https://grass.osgeo.org/grass-stable/manuals/g.region.html) module for this. The spatial extent of the region is defined using the [vector]{.style-parameter} parameter, which is set to the [occurrences]{.style-data} layer. The spatial resolution is taken from the [bio_1@climate]{.style-data} layer by setting the [raster]{.style-parameter} parameter. Finally, the [align]{.style-parameter} parameter ensures that the computational region is aligned with the grid of the [bio_1@climate]{.style-data} raster.


::: {#exm-DzyEuYlZum .hiddendiv}
:::

::: {.panel-tabset}
## {{< fa solid terminal >}}

``` bash
g.region raster=bio_1@climate vector=occurrences align=bio_1@climate
```

## {{< fa brands python >}}

``` python
gs.run_command(
    "g.region",
    raster="bio_1@climate",
    vector="occurrences",
    align="bio_1@climate",
)
```

## {{< fa regular window-restore >}}

To change the region settings, open the `g.region` dialog, and fill in the following parameters:

| Parameter                      | Value                 |
|--------------------------------|-----------------------|
| raster                            | bio_1@climate              |
| align                            | bio_1@climate              |
| vector                         | occurrences |

: {tbl-colwidths="\[40,60\]"}


## {{< fa question >}}

We set the [vector]{.style-parameter} parameter to the [occurrences]{.style-data} layer to define the spatial extent of the region. The [raster]{.style-parameter} parameter is set to the [bio_1@climate]{.style-data} layer, which determines the spatial resolution of the region. Finally, the [align]{.style-parameter} parameter ensures that the region is aligned with the grid of the [bio_1@climate]{.style-data} raster layer.

:::

We can now run the `r.vect.stats` module. The [method]{.style-parameter} parameter specifies which statistic is calculated from the vector points for each raster grid cell. Here, we use [method=n]{.style-parameter} to count the number of points per cell, where [n]{.style-parameter} indicates a point count.

::: {#exm-Xj32c2jubU .hiddendiv}
:::

::: {.panel-tabset}
## {{< fa solid terminal >}}

``` bash
r.vect.stats input=occurrences output=pointdensities method=n
```

## {{< fa brands python >}}

``` python
gs.run_command(
    "r.vect.stats",
    input="occurrences",
    output="pointdensities",
    method="n",
)
```

## {{< fa regular window-restore >}}

To calculate the point densities per grid cell, open the `r.vect.stats` dialog, and use the following parameter settings.

| Parameter | Value                 |
|-----------|-----------------------|
| input     | occurrences |
| output    | pointdensities        |
| method    | n                     |

: {tbl-colwidths="\[40,60\]"}
:::

After completing these steps, we have a raster layer ([pointdensities]{.style-data}) with the number of occurrences per cell. Remember that the extent and resolution of the raster cell is based on the extent of the point data and the resolution of the bioclim layers (@exm-DzyEuYlZum). In the next step, we compute some statistics. To exclude cells with 0 (zero) occurrences, we convert them to NULL using the [r.null](https://grass.osgeo.org/grass-stable/manuals/r.null.html) function. This ensures that only the cells where the species was observed (non-zero values) will be considered in subsequent steps.

::: {#exm-J7MoS70p6m .hiddendiv}
:::

::: {.panel-tabset}
## {{< fa solid terminal >}}

``` bash
r.null map=pointdensities setnull=0
```

## {{< fa brands python >}}

``` python
gs.run_command("r.null", map="pointdensities", setnull=0)
```

## {{< fa regular window-restore >}}

Open the `r.null` dialog, and use the following parameter settings.

| Parameter | Value          |
|-----------|----------------|
| map       | pointdensities |
| setnull   | 0              |

: {tbl-colwidths="\[40,60\]"}
:::

We use [r.univar](https://grass.osgeo.org/grass-stable/manuals/r.univar.html) to compute the range and median of number of observations per grid cell and the [r.boxplot](https://grass.osgeo.org/grass-stable/manuals/addons/r.boxplot.html) addon to visualize the distribution of point densities and to identify possible outliers.

::: {#exm-WtuDMbpLQo .hiddendiv}
:::

::: {.panel-tabset}
## {{< fa solid terminal >}}

``` bash
# Compute raster statistics
r.univar -e map=pointdensities

# Run r.boxplot
r.boxplot -o -h map=pointdensities
```

## {{< fa brands python >}}

``` python
# Compute raster statistics
gs.run_command("r.univar", flags="e", map="pointdensities")

# Run r.boxplot
gs.run_command("r.boxplot", flags="o", map="pointdensities")
```

## {{< fa regular window-restore >}}

Open the `r.univar` dialog, and use the following parameter settings. 

| Parameter                         | Value          |
|-----------------------------------|----------------|
| map                               | pointdensities |
| Calculate extended statistics (e) | ✅             |

: {tbl-colwidths="\[40,60\]"}

<br>Install the `r.boxplot` and run it with the following parameter settings.

| Parameter            | Value          |
|----------------------|----------------|
| Map                  | pointdensities |
| Include outliers (o) | ✅             |

: {tbl-colwidths="\[40,60\]"}

## {{< fa question >}}

The [-e]{.style-parameter} flag tells `r.univar` to calculate extended statistics, like the median.

:::

The results of `r.univar` show that the number of observations per raster cell range from 1 to 346, with a median of 3, and an average of 10. These results and the boxplot in @fig-pointdensitiesboxplot show that even though within the majority of non-NULL raster cells there is only one observation, there are also raster cells with many more observations, up to 240 point observations.

<!---
r.boxplot -o -h map=pointdensities@Erebia_alberganus output=/home/paulo/Nextcloud/Projects/Readers/Ecodiv/sdm_in_grassgis/images/pointdensityboxplot.png plot_dimensions=7,1 --overwrite dpi=100 fontsize=6 median_color="#008021" flier_color="#008021"
-->

![The boxplot shows the range, quartiles, outliers of the point densities.](images/pointdensityboxplot.png){#fig-pointdensitiesboxplot fig-align="left"}

If we look at the attribute table, we'll see that where there are many observations, they often span several years and often involve the same observer. This suggests that certain areas have been surveyed more extensively than others, potentially leading to uneven sampling effort across the species's range.

### Spatially thinning {#sec-spatialthinning}

The results above show that in some areas many observations are clustered close together. This indicates sampling bias and may cause the model to place too much weight on these locations.

A common way to reduce this effect is spatial thinning, also called subsampling [@beck2014a; @steen2021]. Spatial thinning reduces clustering by removing observations that are very close to each other. One implementation is to remove points that occur within a specified minimum distance. This approach is available in the [v.decimate](https://grass.osgeo.org/grass-stable/manuals/v.decimate.html) module.

Another approach is to retain only one occurrence point per raster cell at a chosen resolution, as illustrated in @fig-spatialthinning. This approach is implemented in the `v.maxent.swd` module. 

![Reduce number of sample points to a maximum of 1 point per raster cell.](images/spatialthinning.png){#fig-spatialthinning fig-align="left" width="450"}

For this tutorial, we’ll use the thinning option in the `v.maxent.swd` module. This module will be used later ([@sec-maxentswd]) to prepare the input data for the Maxent analysis, so no action is required at this stage.

::: {.callout-tip collapse="true" title="If you need more control over thinning"}

**Thinning in a separte step**

If you want more control over the thinning process, you can implement a raster-based thinning workflow yourself. This approach separates thinning from background point generation and allows you to inspect the results before modelling. The workflow consists of five steps (example code is provided for illustration; you do not need to run this now).

1. Set the computational region resolution to the desired thinning distance. The spatial resolution controls thinning strength; a coarser resolution results in fewer retained points.
2. Convert the vector point layer to a raster layer using [v.to.rast](https://grass.osgeo.org/grass-stable/manuals/v.to.rast.html). 
3. Converted the raster layer back to a vector point layer with [r.to.vect](https://grass.osgeo.org/grass-stable/manuals/r.to.vect.html). 
4. Restore the original region settings
5. Remove the intermediate raster layer to save space.

``` bash
g.region res=0.025  # example for 0.025 degrees (~2.5 km)
v.to.rast input=occurrences output=occurrences use=value type=point
r.to.vect input=occurrences output=occurrences2 type=point
g.region res=region_aoi@climate # restore original region
g.remove type=raster name=occurrences # remove intermediate raster
```

**When and why to use this approach**

One reason to use this workflow is to experiment with different thinning distances and evaluate their effect on model results. For example, setting the region resolution to 0.05 degrees (~5 km) instead of 0.025 degrees (~2.5 km) results in stronger thinning.

A second reason is that it allows you to inspect the thinned occurrence data before continuing with the modelling. This makes it possible to assess whether the remaining points still represent the species’ distribution adequately and to make a more informed decision about how many background points to generate in @sec-createbgrdpoints.

This step is important because having many more presence points than background points can lead to unstable model estimation and a poor characterisation of the environmental background. For this reason, it is good practice to first check how many presence points are available and, if necessary, determine the number of background points. This is particularly relevant for well-sampled species, where the number of raw presence records may exceed commonly used defaults such as 10,000 background points. In our example, the number of presence points is indeed much larger than 10,000. However, spatial thinning can substantially reduce the number of presence points. In such cases, a background sample of around 10,000 points may be entirely sufficient. 

In other words, the limitation of letting `v.maxent.swd` handle thinning is that in the same step, you need to provide the background points (or tell `v.maxent.swd` how many background points to create), before the final number of retained presence points is known. So you cannot be sure whether the number of background points will be adequate.

In this case, you can assume that the number of points after thinning is considerably less than 10,000. For your own project, you may prefer to perform thinning as a separate step, so that the number of background points can be adjusted once the final number of presence points is known.

:::

## Background points {#sec-studyarea}

Maxent uses *background* points to describe the range of environmental conditions available within the study area. This is done by selecting a large number of locations across the region of interest (shown as green dots in @fig-conceptbackgroundpoints). For each of these locations, the environmental conditions are extracted. Together, these values represent the environmental space of the study area.

Maxent then compares this environmental space with the conditions at the locations where the species was observed (shown as grey dots in @fig-conceptbackgroundpoints). By contrasting these two sets of conditions, the model estimates which environments are more or less suitable for the species.

![Left: A study area with species observations marked by dark gray dots and randomly selected background points marked in green. Right: Scatter and density plots depict how rainfall and temperature are distributed across both the background points (green) and species observations (dark gray). The species prefers areas with higher rainfall, while there is no apparent preference for temperature.](images/study_vs_species-domain.png){#fig-conceptbackgroundpoints fig-align="left"}

### Study area

One of the decisions we need to make is about the boundaries of our study area. We can draw a bounding box or use more complex shapes representing specific boundaries.

::: {.callout-note collapse="true"}
## Importance of the size and shape of the study area

An important decision in species distribution modelling is the size and shape of the study area [@acevedo2012]. The choice of study area determines which environmental conditions are considered available to the species and therefore strongly influences model results.

In a very large study area, environmental gradients tend to be broad. Background points may then include conditions that are far outside the range that the species could realistically tolerate. As a result, the influence of environmental variables operating at smaller spatial scales can be underestimated. Large study areas can also inflate evaluation metrics, such as AUC, by making it easier for the model to distinguish suitable from clearly unsuitable environments.

If the study area is defined too narrowly, for example by focusing mainly on locations where the species has been observed, the model may rely on subtle differences between presence and background points that are not ecologically meaningful. In addition, excluding parts of the species’ true range may cause important environmental gradients to be missed, leading to an incomplete picture of suitable conditions.

A useful guiding concept is the area that has been accessible to the species over relevant time periods. This area is generally the most appropriate extent for model calibration, testing, and comparison [@barveCrucialRoleAccessible2011]. Defining this area is often challenging, as it depends on factors such as dispersal ability, historical processes, environmental continuity, and the presence of barriers.

------------------------------------------------------------------------

**How to**: Depending on how we want to select the background points, we can delimit our study area using the computational region, a MASK or using polygons. These options are described below.
:::

<!----------------------------------------------------------------------------->

We continue working in the mapset [Erebia_alberganus]{.style-data}. The computational region is set using the [region_aoi@climate]{.style-data} region file. This ensures that the background points generated in the next step are restricted to the area of interest defined earlier in @sec-climatedata as [region_aoi]{.style-data}.

Next, we further restrict the study area to land only by applying a MASK based on the [countries@PERMANENT]{.style-data} layer. In GRASS, a MASK is a special raster that limits analyses to selected areas. When a MASK is active, only cells with non-NULL values are included in calculations; all other cells are ignored.

::: {#exm-3XFvGCjQ7i .hiddendiv}
:::

::: {.panel-tabset}
## {{< fa solid terminal >}}

``` bash
# Define the region
g.region region=region_aoi@climate

# Create a MASK
r.mask vector=countries@PERMANENT
```

## {{< fa brands python >}}

``` python
# Set the region to match the region settings in the aoi region file
gs.run_command("g.region", region="region_aoi@climate")

# Create a MASK
gs.run_command("r.mask", vector="countries@PERMANENT")

```

## {{< fa regular window-restore >}}

Run the `g.region` module with the following settings:

| Parameter | Value                |
|-----------|----------------------|
| region    | region_aoi\@climate |

: {tbl-colwidths="\[40,60\]"}

<br>

Create a MASK of the European land areas using `r.mask`:

| Parameter | Value                |
|-----------|----------------------|
| vector    | countries\@PERMANENT |

: {tbl-colwidths="\[40,60\]"}

:::

We have now a new raster layer named [MASK]{.style-data}. The raster cells falling outside the MASK are not included in operations like raster algebra, statistics, or interpolation. In our case, this prevents background points from being generated over sea areas.

![Red outline: the bounds of the computational region. Green: the MASK, which covers the study area.](images/studyarea.png){#fig-studyareas fig-align="left"}

### Background points {#sec-createbgrdpoints}

Now that we have defined the study area, we need to create a vector layer with background points. These will be used to characterize environmental conditions across the study area. The model will compare them with the conditions where the species is present.

::: {.callout-note collapse="true"}
## Background vs pseudo-absence points

Background points are used to characterize the environmental conditions in the study area. They differ from absence points, which explicitly indicate locations where the species was surveyed but not found [e.g. @elith2009; @phillips2009a]. Together with presence data, they can be used to estimate the conditions under which a species is more likely to occur than on average. Background points are commonly selected at random across the study area. However, alternative methods may yield better results [@phillipsSampleSelectionBias2009; @wardPresenceOnlyDataEM2009; @phillipsModelingSpeciesDistributions2008].

A closely related but different concept is that of *pseudo-absences* [@barbet-massin2012]. Pseudo-absence are locations where the species is assumed to be absent, even though no actual survey data confirms this. They are often generated randomly or based on specific criteria to contrast them with presence data (e.g., environmental dissimilarity to presence points). For example, one may select at random sample points throughout the region, excluding areas within a certain distance from presence points. Or sample points may be selected at places unlikely to be suitable for the species.

The advantage of background points over pseudo-absence points is that it requires fewer assumptions and therefore is less prone to bias. And methods such as Maxent can explicitly deal with the overlap between presence and background points [@phillipsOpeningBlackBox2017a]. We will therefore use background points.
:::

There are different ways to create background points. To get a complete representation of the study area, we can convert the [MASK]{.style-data} layer to a vector point layer using the [r.to.vect](https://grass.osgeo.org/grass-stable/manuals/r.to.vect.html) module. However, in our example, this will create a very large point layer with over 7 million locations, which could significantly slow down the modeling process and may well exceed Maxent's capacity to handle such a large dataset. Instead, we create a point layer with randomly selected sample points to represent the environmental conditions in the selected study area.

::: {.callout-note collapse="true"}
## Creating sample background points {#sec-bgpselection}

There are several ways to create background points. One option is to use the [v.maxent.swd](https://grass.osgeo.org/grass-stable/manuals/addons/v.maxent.swd.html) module, which we will use later in this tutorial to prepare the input data for the Maxent model. This module includes an option to generate random background points within the region's bounds and MASK.

For more flexibility, we can create random points in a separate step using for example:

-   The [r.random](https://grass.osgeo.org/grass-stable/manuals/r.random.html) module creates a vector or raster point layer with randomly selected point locations within the current computational region bounds. If there is a [MASK]{.style-data}, points will only be generated within the masked area.

-   The [v.random](https://grass.osgeo.org/grass-stable/manuals/v.random.html) module randomly generates vector points within the current region. If an [restrict]{.style-parameter} vector map is specified with one or more areas (polygons), the location of random points is confined to those areas. By default, the requested number of points are distributed across all areas, but by using the [-a]{.style-parameter} flag, the requested number of points is generated for each individual area, thus allowing for stratified sampling (see examples in the manual page).

-   If you want the random points to be at least a certain distance apart, you can use the [r.random.cells](https://grass.osgeo.org/grass-stable/manuals/r.random.cells.html) module. It generates a random set of raster cells that are at least a certain distance apart. Again, if a MASK is present, random cells will not be generated in masked areas.

-   With the [r.random.weight](https://grass.osgeo.org/grass-stable/manuals/addons/r.random.weight.html) module, you can vary the point density across the region, based on the values of a bias layer. This makes it possible to correct for the effect of sampling bias by creating a background point layer with the same bias as the presence locations [@phillips2009a; @moua2020; @beck2014a].
:::

We'll use the [r.random](https://grass.osgeo.org/grass-stable/manuals/r.random.html) function to generate a point layer named [background_points]{.style-data} with random points within the region's bounds and MASK. The main choice we have to make is the number of sample points. The number of sample points often used is on the order of 10,000, which is what we will use. Note, however, that for larger, more heterogeneous areas, you may need more background points to ensure that all important environmental conditions are well represented [@whitford2024]. Furthermore, if you have a very large number of presence points, you may also want to increase the number of background points accordingly.

::: {#exm-25nmhfEEDF .hiddendiv}
:::

::: {.panel-tabset}
## {{< fa solid terminal >}}

``` bash
r.random input=MASK npoints=10000 vector=background_points seed=5
```

## {{< fa brands python >}}

``` python
gs.run_command(
    "r.random", input="MASK", npoints=10000, vector="background_points", seed=5
)
```

## {{< fa regular window-restore >}}

Open the `r.random`, and use the following parameter settings.

| Parameter | Value             |
|-----------|-------------------|
| input     | MASK              |
| npoints   | 10000             |
| vector    | background_points |
| seed      | 5                 |

: {tbl-colwidths="\[40,60\]"}
:::

## Multicollinearity {#sec-multicollinearity}

Multicollinearity occurs when two or more explanatory variables are highly correlated. This can make it difficult to determine the individual effect of each variable on the species distribution, and redundant variables may add noise to the model without improving its predictive power.

::: {.callout-tip appearance="simple"}
When a species distribution model is built using strongly correlated variables, there are often multiple combinations of variables that produce a similarly good fit to the training data. As a result, different models may perform equally well within the training area. However, when these models are projected to a new geographic region or applied under different climate conditions, their predictions can diverge drastically if the correlation between the explanatory variables in the new region differ from those observed during training.
:::

Maxent, a commonly used SDM tool, is relatively insensitive to multicollinearity because it selects the most informative variables during model training. Yet, excluding highly redundant variables might still help to get a more parsimonious, robust and interpretable model. And on a practical note, it will reduce the time it takes to train the model.

![The bioclim 6 and bioclim 11 variables are highly correlated (r=0.98). This begs the question of how useful it is to use both as predictor variables in the model. You can explore the relation between any two variables yourself using the bivariate scatterplot tool. Click on the ![](images/layer-raster-analyze.png) in the toolbar of the map display.](images/bio6_bio11_scatterplot.png){#fig-bio6bio11scatterplot fig-align="left"}

The variance inflation factor (VIF) is a commonly used method to test for collinearity between predictor variables [@graham2003]. In GRASS, the VIF can be calculated for a set of variables using the add-on [r.vif](https://grass.osgeo.org/grass-stable/manuals/addons/r.vif.html). This addon also allows you to select a subset of variables using a stepwise variable selection procedure. In this procedure, the VIF is computed repeatedly. Each time, the variable with the highest VIF is removed until the highest VIF values are less than a user-defined threshold [@craney2002].

We'll use the stepwise VIF procedure to select the minimum set of bioclimatic variables with a VIF \< 10. We use [n=100,000]{.style-parameter} so that the VIF is performed based on the values of 100,000 random locations. This speeds up the calculation and avoids memory problems. 

::: {#exm-udfds5Bwdr .hiddendiv}
:::

::: {.panel-tabset}
## {{< fa solid terminal >}}

Running the command below gives you a comma separated list of raster layers starting with 'bio' in the mapset 'climate'. Copy that so you can use it as input in `r.vif`. 

``` bash
# Select the input variable
g.list -m type=raster pattern=bio* sep="," mapset=climate
```

Use the output from the previous command to run `r.vif` by replacing [maps=bioclim-layers]{.style-parameter} with the list of raster layers. Alternatively, you can type in the names of the 19 bioclim layers manually.

``` bash
r.vif maps=bioclim-layers seed=5 n=100000 maxvif=10 
```

## {{< fa brands python >}}

``` python
# Select the input variable
layers = gs.list_strings(pattern="bio*", mapset="climate", type="raster")
gs.run_command("r.vif", maps=layers, n=100000, maxvif=10, seed=5)
```

The `list_strings` module provides a convenient wrapper to the `g.list`. The parameters are the same as for the `g.list`. The outcome is a list with the names of all bioclim layers in the climate mapset. These are stored in the variable [layers]{.style-data}, which is then used as input for the `r.vif` module.


## {{< fa regular window-restore >}}

We run the `r.vif`. Make sure to fill in the names of all 19 bioclim variables under the [maps]{.style-parameter} parameter. 

| Parameter | Value                                      |
|-----------|--------------------------------------------|
| maps      | bio_1,bio_2,bio_3 ... bio_17,bio_18,bio_19 |
| n         | 100000                                     |
| maxvif    | 10                                         |
| seed      | 5                                          |

: {tbl-colwidths="\[20,80\]"}

## {{< fa question >}}

To make the results reproducible, use the [seed]{.style-parameter} parameter. You can set any number. Running a function again with the same seed value will yield identical results. 

The VIF is calculated based on the values of raster cells within the current computational region. Therefore, it is important to ensure that the region is set correctly before running `r.vif`. We are interested in the multicollinearity among all 19 bioclimatic variables within the study area, which is already set correctly by the region and MASK in the current mapset [Erebia_alberganus]{.style-data}.
:::

The selected bioclimatic variables in my case are [bio_1]{.style-data}, [bio_2]{.style-data}, [bio_4]{.style-data}, [bio_8]{.style-data}, [bio_9]{.style-data}, [bio_13]{.style-data}, [bio_14]{.style-data}, [bio_15]{.style-data} and [bio_19]{.style-data}. Note that there is a (small) change that your result will show a different combination of variables. This is because the VIF was calculated based on the values of 100,000 randomly selected point locations. Be sure to write down the names of the variables. We'll need them later.

::: {.callout-note appearance="simple"}
The VIF algorithm offers a data-driven method for selecting variables. However, it's important to also consider ecological significance when making selections. For instance, if a species is known to be sensitive to temperatures during the coldest quarter, this variable should be kept regardless of its VIF score. The `r.vif` module includes a [retain]{.style-parameter} parameter that allows you to specify one or more variables to retain during the stepwise selection process. If a retained variable has the highest VIF, the variable with the next highest VIF will be removed instead.
:::

## Export data {#sec-maxentswd}

The last step before we, finally, can start with the actual modeling, is to prepare and export the input dataset for the Maxent model. We'll use the module [v.maxent.swd](https://grass.osgeo.org/grass-stable/manuals/addons/v.maxent.swd.html) for this. The module exports the different layers in the right format for Maxent. The presence and background point layers are exported as so-called [swd]{.style-data} files. Raster layers are exported as [ascii]{.style-data} files.

We'll store the exported data in a new folder within our working directory, called [model_input]{.style-data}. Within this folder, we create a sub-folder [swd01]{.style-data} for the SWD files, and a sub-folder [ascii01]{.style-data} for the ascii files. 

Note, running `v.maxent.swd` may make some time, so be patient.

::: {#exm-ddddddwdr .hiddendiv}
:::

::: {.panel-tabset}
## {{< fa solid terminal >}}

``` bash
# Set the working directory
cd path/to/your/working/directory

# Create a new folder in the working directory
mkdir model_input
mkdir model_input/swd01
mkdir model_input/ascii01

# Export the Maxent input data
v.maxent.swd -t species=occurrences bgp=background_points evp_maps=bio_1,bio_13,bio_14,bio_15,bio_19,bio_2,bio_4,bio_8,bio_9 species_output=model_input/swd01/species.swd bgr_output=model_input/swd01/background_points.swd export_rasters=model_input/ascii01 
```

## {{< fa brands python >}}

``` python
# Set the working directory
os.chdir("path/to/your/working/directory")

# Create a new folder in the working directory
os.makedirs("model_input", exist_ok=True)
os.makedirs("model_input/swd01", exist_ok=True)
os.makedirs("model_input/ascii01", exist_ok=True)

# Export the Maxent input data
gs.run_command(
    "v.maxent.swd",
    flags="t",
    species="occurrences",
    bgp="background_points",
    evp_maps="bio_1,bio_13,bio_14,bio_15,bio_19,bio_2,bio_4,bio_8,bio_9",
    species_output="model_input/swd01/species.swd",
    bgr_output="model_input/swd01/background_points.swd",
    export_rasters="model_input/ascii01"
)
```

## {{< fa regular window-restore >}}

Create the folder [model_input]{.style-data} and in that folder, create the sub-folders [swd01]{.style-data} and [ascii01]{.style-data} using your favorite file manager/explorer. Next, open the `v.maxent.swd` dialog and run it with the following parameter settings:

| Parameter | Value |
|----|----|
| species | occurrences |
| bgp  | background_points |
| evp_maps  | bio_1,bio_2,bio_4,bio_8,bio_9,bio_13,bio_14,bio_15 |
| species_output  | model_input/swd01/species.swd |
| bgr_output  | model_input/swd01/background_points.swd |
| export_rasters  | model_input/ascii01 |
| Thin species and background points (t)  | ✅ |

: {tbl-colwidths="\[50,50\]"}

## {{< fa question >}}

The parameters used in the `v.maxent.swd` module are described below. Note that if you save the file in a sub-folder of your working directory, you can use the relative path.

- [species]{.style-parameter}: point layer with occurrences
- [bgp]{.style-parameter}: point layer with background points. If you don't have one, you can use the [nbgp]{.style-parameter} to generate a user-defined number of background points, respecting the computational region and MASK.
- [evp_maps]{.style-parameter}: The environmental raster layers that you want to include in your model as explanatory variables. Importantly, these should be continuous variables. Use the [evp_cat]{.style-parameter} for categorical variables (e.g., land use map).
- [species_output]{.style-parameter}: The location and file name of the [species swd]{.style-data} file. 
- [bgr_output]{.style-parameter}: The location and file name of the [background swd]{.style-data} file. 
- [export_rasters]{.style-parameter}: The location to which you want to export [environmental raster layers]{.style-data}.You can later on use these raster layers as input in Maxent to create prediction raster layers.

Check out the manual page of [v.maxent.swd](https://grass.osgeo.org/grass-stable/manuals/addons/v.maxent.swd.html) for more details on the parameters and options available.

:::

Make sure to keep clear notes on which files are created, how they were generated, and where they are stored. This will save time and prevent confusion later on, especially when you build multiple models using different combinations of input data. Clear documentation is also essential for reproducibility, both for your own work and for others who may use or review your results.

<br><br>

## Footnotes {.unlisted .unnumbered .hidefootnotes}
